# SISTEMAS DISTRIBUÃDOS - TOLERÃ‚NCIA A FALHAS, AUTO-RECUPERAÃ‡ÃƒO, ESCALONAMENTO HORIZONTAL E MONITORAMENTO REMOTO

Este projeto implementa um sistema distribuÃ­do entre dois notebooks interligados, com foco em monitoramento remoto de um cluster Kubernetes. Utilizamos Prometheus, Grafana, Flask, Sockets e Docker para coleta, envio e visualizaÃ§Ã£o de mÃ©tricas do cluster, incluindo dados em tempo real do HPA e do estado dos pods.
```
ğŸ“ TRABALHO5-SISTEMAS-DISTRIBUIDOS
â”‚
â”œâ”€â”€ ğŸ“ notebookA                     
â”‚   â”œâ”€â”€ ğŸ“ app                      # Aplicativo Flask
â”‚   â”‚   â”œâ”€â”€ main.py                
â”‚   â”‚   â””â”€â”€ requirements.txt       
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ k8s                      # Arquivos de configuraÃ§Ã£o do cluster Kubernetes
â”‚   â”‚   â”œâ”€â”€ components.yaml
â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”œâ”€â”€ hpa.yaml
â”‚   â”‚   â””â”€â”€ service.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ Dockerfile                 # Dockerfile do Notebook A
â”‚   â”œâ”€â”€ k8s_metrics_sender.py      # Script que coleta e envia mÃ©tricas via socket
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ notebookB                     # Recebe mÃ©tricas e expÃµe via Prometheus e Grafana
â”‚   â”œâ”€â”€ ğŸ“ prometheus                
â”‚   â”‚   â””â”€â”€ prometheus.yml
â”‚   â”‚
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ metrics_receiver.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ README.md
```
## âœ… Requisitos

ğŸš™ Docker e Docker Compose

ğŸ¥ Python 3.13.2

ğŸ“¦ Flask 3.1.0

ğŸ“± Minikube / Kubernetes (v1.35.0)

ğŸ“Š Prometheus (latest)

ğŸ“ˆ Grafana (latest)

## ğŸš€ Como Executar o Projeto

### 1ï¸âƒ£ Notebook A 
```
Iniciar Docker
Iniciar minikube (minikube start) pelo PowerShell Adm.
Verificar se o minikube foi iniciado corretamente com: minikube status (deve aparecer running)
cd arquivos
cd notebookA
kubectl apply -f k8s/
cd app
pip install -r requirements.txt
Verificar pods ativos com: kubectl get pods (deve iniciar com 2)
Executar k8s_metrics_sender.py

CASO QUEIRA VER USO DA CPU: kubectl get hpa -w
```

### 2ï¸âƒ£ Notebook B 

```
Iniciar Docker
cd arquivos
cd notebookB
pip install -r requirements.txt
docker-compose up -d
Executar metrics_receiver.py

```
### O Prometheus estarÃ¡ disponÃ­vel na porta 9090, e o Grafana na 3000, para ver o funcionamento:

```
Prometheus: http://localhost:9090
Grafana: http://localhost:3000

Ajustes no Grafana:

UsuÃ¡rio: admin
Senha: admin

Adicionar GrÃ¡ficos. No Grafana:

- Open menu
- Connections
- Data sources
- Add New Data Source
- Seleciona Prometheus
- Default desativado
- Coloca http://localhost:9090 no prometheus server url
- Salva
- Dashboards
- New
- New Dashboards
- Add visualizaÃ§Ã£o
- Prometheus criado

```
### APLICANDO SOBRECARGA ARTIFICIAL EM UM POD 

```
kubectl get pods (ver pods ativos)

kubectl get hpa -w (uso da cpu)

kubectl exec -it <nome do pod> -- /bin/sh
Acessa o terminal interativo (sh) dentro do pod especificado.

apt-get update && apt-get install -y stress
Atualiza a lista de pacotes e instala a ferramenta stress, usada para simular carga de CPU.

stress --cpu 1 --timeout 60
Gera uma carga de CPU utilizando 1 nÃºcleo por 60 segundos, Ãºtil para testar o escalonamento automÃ¡tico (HPA).

```
### âš™ï¸ Funcionamento Interno

```
O Notebook A coleta mÃ©tricas do cluster Kubernetes com kubectl e envia para o Notebook B usando socket.

O Notebook B recebe as mÃ©tricas e as expÃµe na rota /metrics, que o Prometheus consome.

O Grafana acessa o Prometheus para visualizar as mÃ©tricas com dashboards.

As mÃ©tricas monitoradas incluem:

Uso de CPU por pod

Estado dos pods (Running, Pending, Failed)

AÃ§Ãµes disparadas pelo HPA

NÃºmero total de pods ativos
```



ğŸ“† Contribuidores

Luis Eduardo

Francisco AparÃ­cio

Victor MacÃªdo
